"""
Adapter para transformar noticias al tono Althara.

Convierte noticias crudas (raw_summary) en contenido adaptado al estilo
anal√≠tico y profesional de Althara para uso en redes sociales.
"""
from __future__ import annotations

import re
import html
from datetime import datetime
from textwrap import shorten
from typing import Optional, List

# Frases de cierre "gen√©ricas" de Althara
ALTHARA_CLOSERS = [
    "Lo relevante no es el titular, sino qui√©n ajusta posici√≥n antes de que el consenso llegue.",
    "La oportunidad aparece en el desfase entre el dato y la reacci√≥n del mercado visible.",
    "Donde el mercado ve ruido, Althara s√≥lo registra el punto exacto del desplazamiento.",
    "Aqu√≠ importa menos el precio comunicado y m√°s qui√©n tiene acceso al siguiente movimiento.",
]


def _clean_html(text: str) -> str:
    """
    Limpia HTML de un texto, extrayendo solo el contenido de texto puro.
    Tambi√©n elimina metadatos como autores, fechas, botones de compartir, etc.
    Maneja correctamente la codificaci√≥n UTF-8 y las entidades HTML.
    
    Args:
        text: Texto que puede contener HTML
        
    Returns:
        Texto limpio sin tags HTML ni entidades HTML, con codificaci√≥n correcta
    """
    if not text:
        return ""
    
    # Asegurar que el texto est√° en UTF-8
    if isinstance(text, bytes):
        try:
            text = text.decode('utf-8')
        except UnicodeDecodeError:
            try:
                text = text.decode('latin-1')
            except UnicodeDecodeError:
                text = text.decode('utf-8', errors='replace')
    
    # Convertir entidades HTML a caracteres normales (&amp; -> &, &aacute; -> √°, etc.)
    # html.unescape maneja entidades est√°ndar, pero tambi√©n necesitamos manejar casos especiales
    text = html.unescape(text)
    
    # Decodificar entidades HTML adicionales que html.unescape podr√≠a no manejar
    # Reemplazar entidades comunes manualmente si es necesario
    text = text.replace('&amp;', '&')
    text = text.replace('&lt;', '<')
    text = text.replace('&gt;', '>')
    text = text.replace('&quot;', '"')
    text = text.replace('&#39;', "'")
    text = text.replace('&nbsp;', ' ')
    
    # Remover tags HTML (ej: <p>, <a href="...">, etc.)
    # Regex: <[^>]+> busca cualquier cosa entre < y >
    text = re.sub(r'<[^>]+>', '', text)
    
    # Eliminar metadatos comunes de art√≠culos
    # Patrones para eliminar: "AUTOR FECHA - HORA", "Compartir en...", etc.
    patterns_to_remove = [
        r'[A-Z√Å√â√ç√ì√ö√ë][A-Z√Å√â√ç√ì√ö√ë\s]+\s+\d{1,2}\s+[A-Z]{3}\.\s+\d{4}\s*-\s*\d{2}:\d{2}',  # "BEATRIZ AMIGOT 27 NOV. 2025 - 09:39"
        r'Compartir en (Facebook|Twitter|LinkedIn|WhatsApp)',  # Botones de compartir
        r'Enviar por email',
        r'DREAMSTIME|GETTY|SHUTTERSTOCK|ISTOCK',  # Fuentes de im√°genes
        r'EXPANSION|EL PA√çS|CINCO D√çAS',  # Nombres de medios repetidos
        r'Vistas del|Imagen de|Foto de',  # Descripciones de im√°genes
        r'\b\d{1,2}\s+[A-Z]{3}\.\s+\d{4}\s*-\s*\d{2}:\d{2}\b',  # Fechas sueltas
        r'Periodista y Coordinadora editorial',  # Cargos editoriales
        r'\d{2}/\d{2}/\d{4}',  # Fechas en formato DD/MM/YYYY
    ]
    
    for pattern in patterns_to_remove:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # Eliminar l√≠neas que solo contienen may√∫sculas (t√≠tulos de secci√≥n)
    lines = text.split('\n')
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        # Si la l√≠nea tiene m√°s de 3 palabras en may√∫sculas consecutivas, probablemente es un t√≠tulo
        if not re.match(r'^[A-Z√Å√â√ç√ì√ö√ë\s]{20,}$', line):
            cleaned_lines.append(line)
    text = ' '.join(cleaned_lines)
    
    # Limpiar caracteres de reemplazo Unicode () - estos indican problemas de codificaci√≥n
    # Intentar reparar caracteres comunes mal codificados
    text = text.replace('\ufffd', '')  # Eliminar caracteres de reemplazo Unicode
    text = text.replace('', '')  # Eliminar caracteres de reemplazo si est√°n presentes
    
    # Reparar caracteres acentuados comunes que se hayan perdido por problemas de codificaci√≥n
    # Patrones comunes donde se pierden acentos en espa√±ol
    accent_fixes = [
        (r'\bneuropsicloga\b', 'neuropsic√≥loga'),
        (r'\bMnica\b', 'M√≥nica'),
        (r'\bcientfica\b', 'cient√≠fica'),
        (r'\bdcadas\b', 'd√©cadas'),
        (r'\bmbito\b', '√°mbito'),
        (r'\bpsicloga\b', 'psic√≥loga'),
        (r'\beducacin\b', 'educaci√≥n'),
        (r'\bdise√±ar\b', 'dise√±ar'),  # Ya est√° bien, pero por si acaso
        (r'\bsegn\b', 'seg√∫n'),
        (r'\bcmo\b', 'c√≥mo'),
        (r'\bqu\b', 'qu√©'),
        (r'\bdnde\b', 'd√≥nde'),
        (r'\bcuando\b', 'cu√°ndo'),  # Solo si est√° en contexto de pregunta
        (r'\barchitectura\b', 'arquitectura'),  # Por si viene en ingl√©s
    ]
    
    for pattern, replacement in accent_fixes:
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    
    # Reparar palabras comunes sin acento (solo si no tienen acento y deber√≠an tenerlo)
    # Esto es m√°s conservador - solo repara casos muy comunes
    common_fixes = {
        'psicologa': 'psic√≥loga',
        'psicologo': 'psic√≥logo',
        'arquitecta': 'arquitecta',  # Ya est√° bien
        'arquitecto': 'arquitecto',  # Ya est√° bien
        'educacion': 'educaci√≥n',
        'especializada': 'especializada',  # Ya est√° bien
        'especializado': 'especializado',  # Ya est√° bien
    }
    
    # Solo aplicar si la palabra est√° sola (no como parte de otra palabra)
    for wrong, correct in common_fixes.items():
        text = re.sub(r'\b' + wrong + r'\b', correct, text, flags=re.IGNORECASE)
    
    # Limpiar espacios m√∫ltiples y saltos de l√≠nea
    text = re.sub(r'\s+', ' ', text)
    
    # Limpiar espacios al inicio y final
    text = text.strip()
    
    return text


def _build_fact_line(title: str, raw_summary: Optional[str]) -> str:
    """
    Construye la primera l√≠nea: descripci√≥n fr√≠a del hecho.
    """
    base = title.strip()
    
    if raw_summary:
        # Limpiar HTML del raw_summary antes de combinarlo
        cleaned_summary = _clean_html(raw_summary)
        combined = f"{title.strip()}. {cleaned_summary}"
        # recortamos para no generar un bloque eterno
        fact = shorten(combined, width=220, placeholder="‚Ä¶")
    else:
        fact = base
    
    # Algunos prefijos neutros que suavizan titulares muy period√≠sticos
    lower = fact.lower()
    
    if lower.startswith("el ") or lower.startswith("la ") or lower.startswith("los ") or lower.startswith("las "):
        return fact
    if lower.startswith("en "):
        return fact
    
    # Si no empieza con algo neutro, a√±adimos un marco
    return f"Los √∫ltimos datos apuntan a lo siguiente: {fact}"


def _build_strategic_line(category: Optional[str]) -> str:
    """
    Segunda l√≠nea: lectura estrat√©gica en funci√≥n de la categor√≠a.
    """
    if category is None:
        category = ""
    
    cat = category.upper()
    
    if cat in {"PRECIOS_VIVIENDA"}:
        return (
            "Detr√°s de la cifra, el patr√≥n es un ajuste entre oferta limitada y demanda que a√∫n no ha reprecificado del todo el riesgo del ciclo."
        )
    
    if cat in {"FONDOS_INVERSION_INMOBILIARIA", "MOVIMIENTOS_GRANDES_TENEDORES", "GRANDES_INVERSIONES_INMOBILIARIAS"}:
        return (
            "El movimiento no es aislado: refleja una rotaci√≥n silenciosa de capital hacia activos donde la asimetr√≠a de informaci√≥n sigue siendo aprovechable."
        )
    
    if cat in {"NOTICIAS_HIPOTECAS"}:
        return (
            "El repliegue y la reconfiguraci√≥n del cr√©dito redefinen qui√©n puede seguir operando con ventaja en el pr√≥ximo tramo del ciclo."
        )
    
    if cat in {"NOTICIAS_BOE_SUBASTAS", "NOTICIAS_DESAHUCIOS"}:
        return (
            "Estas entradas formalizan stock, pero sobre todo dibujan el mapa de activos donde el mercado a√∫n no ha fijado un precio de consenso."
        )
    
    if cat in {"NOTICIAS_LEYES_OKUPAS", "NORMATIVAS_VIVIENDAS", "FALTA_VIVIENDA"}:
        return (
            "La regulaci√≥n no solo corrige desequilibrios aparentes, sino que reordena qu√© actores conservan acceso operativo real al mercado."
        )
    
    if cat in {"NOTICIAS_CONSTRUCCION", "PRECIOS_MATERIALES", "PRECIOS_SUELO", "NOVEDADES_CONSTRUCCION"}:
        return (
            "Los costes y las reglas del juego de la obra redefinen la frontera entre proyectos viables y meros ejercicios te√≥ricos de rentabilidad."
        )
    
    if cat in {"CONSTRUCCION_MODULAR", "NOTICIAS_URBANIZACION"}:
        return (
            "La industrializaci√≥n y el planeamiento no solo cambian formas, comprimen plazos y riesgos all√≠ donde el capital est√© dispuesto a anticiparse."
        )
    
    if cat in {"FUTURO_SECTOR_INMOBILIARIO", "BURBUJA_INMOBILIARIA"}:
        return (
            "M√°s que un dato aislado, es una l√≠nea m√°s en el gr√°fico de tensiones acumuladas que el consenso a√∫n no ha terminado de asumir."
        )
    
    if cat in {"NOTICIAS_INMOBILIARIAS"}:
        return (
            "No es una noticia suelta: es otra pieza en la secuencia que reordena precios, actores y acceso efectivo a oportunidades reales."
        )
    
    # fallback gen√©rico
    return (
        "El dato no va solo: se suma a una secuencia de se√±ales que reordenan qui√©n tiene visibilidad real y qui√©n llega tarde a cada movimiento."
    )


def _pick_closer(index_seed: Optional[int] = None) -> str:
    """
    Tercera l√≠nea: cierre Althara. Puedes usar una rotaci√≥n simple en lugar de random puro,
    para que sea m√°s determinista si quieres.
    """
    if index_seed is None:
        # muy simple: usa el timestamp actual para variar un poco
        index_seed = int(datetime.utcnow().timestamp())
    
    idx = index_seed % len(ALTHARA_CLOSERS)
    return ALTHARA_CLOSERS[idx]


def _extract_key_data(raw_summary: Optional[str]) -> List[str]:
    """
    Extrae datos clave del raw_summary: n√∫meros, porcentajes, precios, fechas importantes.
    
    Args:
        raw_summary: Resumen original de la noticia
        
    Returns:
        Lista de strings con datos clave encontrados (m√°ximo 5)
    """
    if not raw_summary:
        return []
    
    key_data = []
    text = _clean_html(raw_summary)
    
    # Patrones para extraer datos relevantes
    patterns = [
        # Porcentajes: "5%", "12,5%", "aument√≥ un 15%"
        (r'(\d+[.,]?\d*\s*%)', 'Porcentaje'),
        # Precios: "‚Ç¨500.000", "1.2 millones", "‚Ç¨1.500/m¬≤"
        (r'(‚Ç¨\s*\d+[.,]?\d*[.,]?\d*\s*(?:millones?|miles?|/m¬≤)?)', 'Precio'),
        # N√∫meros grandes: "1.500 viviendas", "2 millones de euros"
        (r'(\d+[.,]?\d*[.,]?\d*\s*(?:millones?|miles?|millones? de|viviendas?|propiedades?|euros?))', 'Cantidad'),
        # A√±os: "2025", "en 2024"
        (r'(\b(?:20\d{2}|19\d{2})\b)', 'A√±o'),
        # Variaciones: "subi√≥ un 10%", "baj√≥ 5 puntos"
        (r'((?:subi√≥|baj√≥|aument√≥|disminuy√≥|creci√≥|descendi√≥)\s+(?:un\s+)?\d+[.,]?\d*\s*(?:%|puntos?))', 'Variaci√≥n'),
    ]
    
    found_data = set()  # Para evitar duplicados
    
    for pattern, label in patterns:
        matches = re.finditer(pattern, text, re.IGNORECASE)
        for match in matches:
            data_point = match.group(1).strip()
            # Limpiar y formatear
            data_point = re.sub(r'\s+', ' ', data_point)
            if data_point and len(data_point) < 50:  # Evitar matches muy largos
                found_data.add(data_point)
    
    # Convertir a lista y limitar a 5 elementos m√°s relevantes
    key_data = list(found_data)[:5]
    
    return key_data


def _extract_keywords(title: str, raw_summary: Optional[str]) -> List[str]:
    """
    Extrae palabras clave relevantes y coherentes del t√≠tulo y raw_summary.
    Se enfoca en t√©rminos inmobiliarios, ubicaciones y conceptos clave.
    
    Args:
        title: T√≠tulo de la noticia
        raw_summary: Resumen original (opcional)
        
    Returns:
        Lista de palabras clave relevantes (m√°ximo 6-8)
    """
    # Palabras comunes a excluir (ampliado)
    stop_words = {
        'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
        'de', 'del', 'en', 'a', 'al', 'con', 'por', 'para', 'sobre',
        'es', 'son', 'fue', 'fueron', 'ser', 'estar', 'tener', 'haber',
        'que', 'cual', 'cuales', 'quien', 'quienes', 'donde', 'cuando',
        'como', 'm√°s', 'menos', 'muy', 'tan', 'tanto', 'tambi√©n', 'tampoco',
        'este', 'esta', 'estos', 'estas', 'ese', 'esa', 'esos', 'esas',
        'a√±o', 'a√±os', 'mes', 'meses', 'd√≠a', 'd√≠as', 'vez', 'veces',
        'seg√∫n', 'todos', 'todas', 'cada', 'todo', 'toda',
        'puede', 'pueden', 'debe', 'deben', 'hace', 'hacen',
        'sido', 'estado', 'estado', 'sido',
    }
    
    # T√©rminos inmobiliarios relevantes (prioridad alta)
    real_estate_terms = {
        'vivienda', 'viviendas', 'inmobiliario', 'inmobiliaria', 'inmobiliarias',
        'hipoteca', 'hipotecas', 'hipotecario', 'hipotecaria',
        'precio', 'precios', 'valor', 'valores', 'coste', 'costes',
        'alquiler', 'alquileres', 'renta', 'rentas',
        'compra', 'venta', 'comprar', 'vender', 'compraventa', 'compraventas',
        'mercado', 'mercados', 'sector', 'sectores',
        'propiedad', 'propiedades', 'inmueble', 'inmuebles',
        'construcci√≥n', 'construcciones', 'obra', 'obras',
        'promoci√≥n', 'promociones', 'desarrollo', 'desarrollos',
        'inversi√≥n', 'inversiones', 'inversor', 'inversores',
        'subasta', 'subastas', 'desahucio', 'desahucios',
        'okupaci√≥n', 'okupaciones', 'okupa', 'okupas',
        'normativa', 'normativas', 'ley', 'leyes', 'regulaci√≥n',
    }
    
    # Ubicaciones importantes (prioridad media)
    locations = {
        'madrid', 'barcelona', 'valencia', 'sevilla', 'bilbao', 'zaragoza',
        'm√°laga', 'murcia', 'palma', 'las palmas', 'granada', 'alicante',
        'valladolid', 'c√≥rdoba', 'vigo', 'gij√≥n', 'hospitalet', 'vitoria',
        'castilla', 'le√≥n', 'andaluc√≠a', 'catalu√±a', 'comunidad valenciana',
        'galicia', 'pa√≠s vasco', 'asturias', 'cantabria', 'navarra',
        'espa√±a', 'espa√±ol', 'europa', 'europeo',
    }
    
    # Combinar y limpiar texto
    combined_text = title.lower()
    if raw_summary:
        cleaned = _clean_html(raw_summary).lower()
        combined_text += " " + cleaned
    
    # Extraer palabras (solo palabras de 4+ caracteres)
    words = re.findall(r'\b[a-z√°√©√≠√≥√∫√±√º]{4,}\b', combined_text)
    
    # Contar frecuencia de palabras para priorizar las m√°s relevantes
    word_freq = {}
    for word in words:
        if word not in stop_words:
            word_freq[word] = word_freq.get(word, 0) + 1
    
    # Filtrar y priorizar
    keywords = []
    seen = set()
    
    # Prioridad 1: T√©rminos inmobiliarios (m√°s relevantes)
    for word in sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True):
        if word in real_estate_terms and word not in seen:
            keywords.append(word)
            seen.add(word)
            if len(keywords) >= 5:
                break
    
    # Prioridad 2: Ubicaciones
    if len(keywords) < 8:
        for word in sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True):
            if word in locations and word not in seen:
                keywords.append(word)
                seen.add(word)
                if len(keywords) >= 8:
                    break
    
    # Prioridad 3: Conceptos clave (sustantivos importantes)
    if len(keywords) < 8:
        for word in sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True):
            if word not in seen and len(word) >= 5:
                # Priorizar sustantivos (terminaciones comunes en espa√±ol)
                if any(word.endswith(suffix) for suffix in ['ci√≥n', 'si√≥n', 'dad', 'tad', 'tud', 'aje', 'ismo', 'miento']):
                    keywords.append(word)
                    seen.add(word)
                    if len(keywords) >= 8:
                        break
    
    # Si a√∫n no tenemos suficientes, a√±adir palabras m√°s frecuentes
    if len(keywords) < 6:
        for word in sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True):
            if word not in stop_words and word not in seen and len(word) >= 5 and word_freq[word] >= 2:
                keywords.append(word)
                seen.add(word)
                if len(keywords) >= 6:
                    break
    
    return keywords[:8]


def _build_extended_summary(title: str, raw_summary: Optional[str]) -> str:
    """
    Construye el contenido completo de la noticia, limpiando metadatos pero manteniendo
    toda la informaci√≥n relevante. No recorta el contenido, solo lo limpia.
    
    Args:
        title: T√≠tulo de la noticia
        raw_summary: Resumen original (opcional)
        
    Returns:
        Contenido completo limpio de la noticia
    """
    if not raw_summary:
        return title.strip()
    
    # Limpiar el resumen (elimina HTML, metadatos, etc.)
    cleaned_summary = _clean_html(raw_summary)
    
    # Eliminar repeticiones del t√≠tulo al inicio del resumen
    title_lower = title.lower().strip()
    cleaned_lower = cleaned_summary.lower().strip()
    
    # Si el resumen empieza con el t√≠tulo completo, eliminarlo
    if cleaned_lower.startswith(title_lower):
        cleaned_summary = cleaned_summary[len(title):].strip()
        # Eliminar puntos, comas y espacios al inicio
        cleaned_summary = re.sub(r'^[.,\s]+', '', cleaned_summary)
    
    # Tambi√©n buscar si el t√≠tulo aparece como frase completa m√°s adelante y eliminarlo
    # Esto maneja casos donde el t√≠tulo se repite en medio del texto
    title_words = title_lower.split()
    if len(title_words) > 3:
        # Buscar la primera parte del t√≠tulo (primeras 4-5 palabras)
        title_start = ' '.join(title_words[:min(5, len(title_words))])
        # Si aparece al inicio del texto limpio, eliminarlo
        if cleaned_lower.startswith(title_start):
            # Encontrar d√≥nde termina esta repetici√≥n
            idx = cleaned_summary.lower().find(title_start)
            if idx == 0:
                # Avanzar hasta despu√©s de la repetici√≥n
                remaining = cleaned_summary[len(title_start):].strip()
                # Buscar el siguiente punto o espacio significativo
                next_space = remaining.find(' ')
                if next_space > 0:
                    cleaned_summary = remaining[next_space:].strip()
                else:
                    cleaned_summary = remaining
                cleaned_summary = re.sub(r'^[.,\s]+', '', cleaned_summary)
    
    # Eliminar repeticiones de frases comunes al inicio
    words = cleaned_summary.split()
    if len(words) > 15:
        # Buscar si las primeras 3-5 palabras se repiten m√°s adelante
        for i in range(3, min(8, len(words))):
            first_phrase = ' '.join(words[:i]).lower()
            # Buscar si esta frase aparece m√°s adelante (despu√©s de la posici√≥n i)
            remaining_text = ' '.join(words[i:]).lower()
            if first_phrase in remaining_text:
                # Eliminar la primera ocurrencia
                cleaned_summary = ' '.join(words[i:])
                break
    
    # Eliminar frases de secci√≥n repetidas (ej: "Mercado Inmobiliario")
    section_phrases = ['mercado inmobiliario', 'noticias inmobiliarias', 'econom√≠a inmobiliaria']
    for phrase in section_phrases:
        # Eliminar si aparece al inicio
        if cleaned_summary.lower().startswith(phrase):
            cleaned_summary = cleaned_summary[len(phrase):].strip()
            cleaned_summary = re.sub(r'^[.,\s]+', '', cleaned_summary)
    
    # Eliminar repeticiones completas del texto (si el texto se repite palabra por palabra)
    words = cleaned_summary.split()
    if len(words) > 20:
        # Buscar si las primeras 10 palabras aparecen duplicadas m√°s adelante
        first_10_words = ' '.join(words[:10]).lower()
        # Buscar esta frase en el resto del texto
        remaining_text = ' '.join(words[10:]).lower()
        if first_10_words in remaining_text:
            # Encontrar d√≥nde termina la primera ocurrencia
            idx = remaining_text.find(first_10_words)
            if idx > 0:
                # Mantener solo hasta donde empieza la repetici√≥n
                cleaned_summary = ' '.join(words[:10 + idx // 2])  # Aproximado
            else:
                # Si est√° al inicio, eliminar la primera ocurrencia
                cleaned_summary = ' '.join(words[10:])
    
    # Combinar t√≠tulo y contenido
    combined = f"{title.strip()}. {cleaned_summary}"
    
    # Formatear en p√°rrafos legibles: dividir por puntos seguidos de espacio
    # Dividir en oraciones (por puntos, signos de exclamaci√≥n o interrogaci√≥n)
    sentences = re.split(r'([.!?])\s+', combined)
    
    # Reconstruir oraciones con sus signos de puntuaci√≥n
    reconstructed_sentences = []
    for i in range(0, len(sentences) - 1, 2):
        if i + 1 < len(sentences):
            sentence = sentences[i] + sentences[i + 1]
            sentence = sentence.strip()
            if sentence:
                reconstructed_sentences.append(sentence)
    
    # Si no se pudieron dividir bien, usar el m√©todo simple
    if not reconstructed_sentences:
        sentences = re.split(r'\.\s+', combined)
        reconstructed_sentences = [s.strip() + '.' for s in sentences if s.strip()]
    
    # Agrupar oraciones en p√°rrafos de 2-3 oraciones cada uno para mejor legibilidad
    paragraphs = []
    current_paragraph = []
    
    for sentence in reconstructed_sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        # Asegurar que termina con puntuaci√≥n
        if not sentence.endswith(('.', '!', '?', '‚Ä¶')):
            sentence += '.'
        
        current_paragraph.append(sentence)
        
        # Crear p√°rrafo cada 2-3 oraciones, o si la oraci√≥n es muy larga (>120 chars)
        if len(current_paragraph) >= 3 or (len(sentence) > 120 and len(current_paragraph) >= 2):
            paragraphs.append(' '.join(current_paragraph))
            current_paragraph = []
    
    # A√±adir el √∫ltimo p√°rrafo si tiene contenido
    if current_paragraph:
        paragraphs.append(' '.join(current_paragraph))
    
    # Si no se pudieron crear p√°rrafos (texto muy corto), devolver tal cual pero formateado
    if not paragraphs:
        # Limitar solo si es extremadamente largo
        if len(combined) > 5000:
            truncated = combined[:5000]
            last_period = truncated.rfind('. ')
            if last_period > 4500:
                combined = combined[:last_period + 1] + "‚Ä¶"
            else:
                combined = truncated + "‚Ä¶"
        return combined
    
    # Unir p√°rrafos con doble salto de l√≠nea para mejor legibilidad
    formatted_text = '\n\n'.join(paragraphs)
    
    # Limitar solo si es extremadamente largo (m√°s de 5000 caracteres)
    if len(formatted_text) > 5000:
        # Mantener p√°rrafos completos hasta el l√≠mite
        truncated_paragraphs = []
        total_length = 0
        for para in paragraphs:
            if total_length + len(para) + 2 > 5000:  # +2 por el salto de l√≠nea
                break
            truncated_paragraphs.append(para)
            total_length += len(para) + 2
        formatted_text = '\n\n'.join(truncated_paragraphs) + "‚Ä¶"
    
    return formatted_text


def build_althara_summary(
    title: str,
    raw_summary: Optional[str],
    category: Optional[str],
    seed: Optional[int] = None,
) -> str:
    """
    Construye un resumen completo estructurado con el tono y estilo de Althara.
    
    Estructura:
    - RESUMEN: Contenido ampliado del raw_summary
    - AN√ÅLISIS ALTHARA: Lectura estrat√©gica seg√∫n categor√≠a
    - DATOS CLAVE: N√∫meros, porcentajes, precios, fechas relevantes
    - PALABRAS CLAVE: T√©rminos relevantes extra√≠dos
    
    Args:
        title: T√≠tulo de la noticia
        raw_summary: Resumen original de la fuente (opcional)
        category: Categor√≠a de la noticia (opcional)
        seed: Semilla para rotar los cierres (opcional)
        
    Returns:
        Texto adaptado al tono Althara con estructura completa
    """
    sections = []
    
    # 1. CONTENIDO COMPLETO (formateado en p√°rrafos)
    full_content = _build_extended_summary(title, raw_summary)
    sections.append("üìä CONTENIDO")
    sections.append("")
    sections.append(full_content)
    sections.append("")
    sections.append("")  # L√≠nea en blanco adicional para separaci√≥n
    
    # 2. AN√ÅLISIS ALTHARA
    strategic_line = _build_strategic_line(category)
    sections.append("üí° AN√ÅLISIS ALTHARA")
    sections.append("")
    sections.append(strategic_line)
    sections.append("")
    sections.append("")  # L√≠nea en blanco adicional
    
    # 3. DATOS CLAVE
    key_data = _extract_key_data(raw_summary)
    if key_data:
        sections.append("üìà DATOS CLAVE")
        sections.append("")
        for data in key_data:
            sections.append(f"‚Ä¢ {data}")
        sections.append("")
        sections.append("")  # L√≠nea en blanco adicional
    
    # 4. PALABRAS CLAVE
    keywords = _extract_keywords(title, raw_summary)
    if keywords:
        sections.append("üîë PALABRAS CLAVE")
        sections.append("")
        keywords_str = " ‚Ä¢ ".join(keywords)
        sections.append(keywords_str)
    
    return "\n".join(sections)
